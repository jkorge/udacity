{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Determination\n",
    "--------------------------------------------------------------------------------------------------------------------------------\n",
    "Use this notebook to determing the best model for detecting vehicles in an image. After defining a set of utility functions, a LinearSVC is fit to the data according to a set of feature extraction parameters. To determine the best assembly of parameters use the following pipeline:\n",
    "* Set parameters determining which features to extract\n",
    "* Pull features from available data\n",
    "* Label features\n",
    "* train_test_split the data\n",
    "* Shuffle the training data\n",
    "* Fit a scaler to the training data\n",
    "* Save the scaler\n",
    "* Scale the training and test data\n",
    "* Fit a LinearSVC to the training data\n",
    "* Measure the classifier's accuracy on the test data\n",
    "* Repeat with new set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.ndimage.measurements import label\n",
    "from skimage.feature import hog\n",
    "import time\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(img_list, gray_maps, titles=None, axes_off=True, imsize=(20,20), bgr=None):\n",
    "    '''\n",
    "    Utility for examining results from project functions. Plots images\n",
    "    Input: img_list = List of images\n",
    "           gray_maps = List of boolans indicating which of img_list is grayscale\n",
    "           titles = List of strings indicating titles of each image\n",
    "           axes_off = Boolean flag indicating if plot axes should be hidden\n",
    "           imsize = Int tuple of image size\n",
    "           bgr = List of booleans indicating which of img_list is in bgr\n",
    "    Output: ax = axis object from plot\n",
    "    '''\n",
    "    if bgr == None:\n",
    "        bgr = [False for i in range(len(img_list))]\n",
    "    \n",
    "    if len(img_list)==1:\n",
    "        f, ax = plt.subplots(1, 1, figsize=imsize)\n",
    "        if gray_maps[0]:\n",
    "            ax.imshow(img_list[0], cmap='gray')\n",
    "        elif bgr:\n",
    "            ax.imshow(img_list[0][:,:,::-1])\n",
    "        else:\n",
    "            ax.imshow(img_list[0])\n",
    "        if axes_off:\n",
    "            ax.axis('off')\n",
    "        if titles != None:\n",
    "            ax.set_title(titles[0], fontsize=20)\n",
    "    else:\n",
    "        f, ax = plt.subplots(1, len(img_list), figsize=imsize)\n",
    "        f.tight_layout\n",
    "        ax = ax.ravel()\n",
    "        for i in range(len(img_list)):\n",
    "            if gray_maps[i]:\n",
    "                ax[i].imshow(img_list[i], cmap='gray')\n",
    "            elif bgr[i]:\n",
    "                ax[i].imshow(img_list[i][:,:,::-1])\n",
    "            else:\n",
    "                ax[i].imshow(img_list[i])\n",
    "            if axes_off:\n",
    "                ax[i].axis('off')\n",
    "            if titles != None:\n",
    "                ax[i].set_title(titles[i], fontsize=20)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    '''\n",
    "    Create a histogram of values for each color channel in an image\n",
    "    Inputs: img = Image\n",
    "            nbins = Number of bins to sort values into\n",
    "            bins_range = Range of values image pixels may have\n",
    "    Output: Array of histogram values\n",
    "    '''\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    \n",
    "    # Concatenate the histograms into a single feature vector and return\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    \n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "    '''\n",
    "    Bin the pixels of an image into those of a smaller image using cv2's default bilinear interpolation\n",
    "    Inputs: img = Image\n",
    "            size = 2-tuple of binned image dimensions\n",
    "    Output: Flattened array of pixel values from binned image\n",
    "    '''\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_color(img, conv='BGR2YCrCb'):\n",
    "    return cv2.cvtColor(img, eval('cv2.COLOR_'+conv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    '''\n",
    "    Shorthand for producing a histogram-oriented graph (HOG) for an image\n",
    "    Inputs: img = Image\n",
    "            orient = Number of gradient orientations to bin values into\n",
    "            pix_per_cell = Number of pixels per cell\n",
    "            cell_per_block = Number of cells per block\n",
    "            vis = Boolean to toggle return of an image of the graph\n",
    "            feature_vec = Boolean to indicate whether this computation is meant to return a single feature vector\n",
    "    Output: features (if vis) = HOG values\n",
    "            hog_image (if vis) = Image of HOG\n",
    "            output (if not vis) = HOG values\n",
    "    '''\n",
    "    # Comput the HOG with the given parameters\n",
    "    # Uses 'L2-Hys' for the normalization and sets transform_sqrt to True\n",
    "    output = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                 cells_per_block=(cell_per_block, cell_per_block), block_norm= 'L2-Hys',\n",
    "                 transform_sqrt=True, visualise=vis, feature_vector=feature_vec)\n",
    "\n",
    "    # Return two outputs if vis == True\n",
    "    if vis == True:\n",
    "        features, hog_image = output[0], output[1]\n",
    "        return features, hog_image\n",
    "    # Otherwise return one output\n",
    "    else:\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(imgs, color_space='BGR',\n",
    "                     spatial_size=(32, 32), hist_bins=32, hist_range=(0, 256),\n",
    "                     orient=9, pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    '''\n",
    "    Extract the HOG, spatial bin, and/or color histogram features from a list of images\n",
    "    Inputs: imgs = List of image file-paths\n",
    "            color_space = String identifying the color space from which the features should be extracted\n",
    "            spatial_size = 2-Tuple indicating bin counts in x and y respectively\n",
    "            hist_bins = Number of bins into which color values should be binned\n",
    "            hist_range = Range of values image pixels may have\n",
    "            orient = Number of gradient orientations to bin values into\n",
    "            pix_per_cell = Number of pixels per cell\n",
    "            cell_per_block = Number of cells per block\n",
    "            hog_channel = Image color-channel(s) to use for computing HOG (Pass string 'ALL' to use all channels)\n",
    "            spatial_feat = Boolean indicating whether or not spatial features should be extracted\n",
    "            hist_feat = Boolean indicating whether or not color features should be extracted\n",
    "            hog_feat = Boolean indicating whether or not HOG features should be computed\n",
    "    Outputs: List of each image's feature vector\n",
    "    '''\n",
    "    \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    \n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        \n",
    "        file_features = []\n",
    "        \n",
    "        # Read in the image\n",
    "        image = cv2.imread(file)\n",
    "        \n",
    "        # Apply color conversion if necessary\n",
    "        if color_space != 'BGR':\n",
    "            feature_image = convert_color(image, 'BGR2'+color_space)\n",
    "        else:\n",
    "            feature_image = np.copy(image)   \n",
    "        \n",
    "        # Get spatail features\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        \n",
    "        # Get color features\n",
    "        if hist_feat == True:\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "            file_features.append(hist_features)\n",
    "            \n",
    "        # Get HOG features\n",
    "        if hog_feat == True:\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "                \n",
    "            file_features.append(hog_features)\n",
    "        \n",
    "        # Add this image's features to the list\n",
    "        features.append(np.concatenate(file_features))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_measure(clfname, cars, notcars, cols=[], keycols=[], cspace='BGR',\n",
    "                  hog_channel='ALL', orient=9, pix_per_cell=8, cell_per_block=2,\n",
    "                  spatial_params=32, hist_params=32,\n",
    "                  spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    test_params = dict.fromkeys(cols)\n",
    "    \n",
    "    colorspace = cspace\n",
    "    spatial_size = (spatial_params, spatial_params)\n",
    "    hist_bins = hist_params\n",
    "    y_start_stop = [400, None]\n",
    "    \n",
    "    print('Extracting features...')\n",
    "    # Extract features\n",
    "    t0 = time.time()\n",
    "    car_features = extract_features(cars, color_space=colorspace, orient=orient,\n",
    "                                    pix_per_cell=pix_per_cell, cell_per_block=cell_per_block,\n",
    "                                    hog_channel=hog_channel, spatial_size=spatial_size,\n",
    "                                    hist_bins=hist_bins, hist_feat=hist_feat,\n",
    "                                    spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "    notcar_features = extract_features(notcars, color_space=colorspace, orient=orient,\n",
    "                                       pix_per_cell=pix_per_cell, cell_per_block=cell_per_block,\n",
    "                                       hog_channel=hog_channel, spatial_size=spatial_size,\n",
    "                                       hist_bins=hist_bins, hist_feat=hist_feat,\n",
    "                                       spatial_feat=spatial_feat, hog_feat=hog_feat)\n",
    "    t1 = time.time()\n",
    "    print('%.3f seconds to extract features.\\n' % (t1-t0))\n",
    "    test_params[cols[0]] = round(t1-t0, 3)\n",
    "    \n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "    \n",
    "    # Shuffle and split up data into randomized training and test sets\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X, y = shuffle(X, y, random_state=rand_state)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "    t0 = time.time()\n",
    "    # Fit a per-column scaler\n",
    "    print('Fitting scaler...')\n",
    "    X_scaler = StandardScaler().fit(X_train)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    print('%.3f seconds to fit scaler.\\n' % (t1-t0))\n",
    "    test_params[cols[1]] = round(t1-t0, 3)\n",
    "    \n",
    "    # Save the scaler for use in other kernels\n",
    "    print('Saving scaler...')\n",
    "    joblib.dump(X_scaler, clfname+'_scaler.p')\n",
    "    print('Scaler saved.')\n",
    "\n",
    "    # Apply the scaler to X\n",
    "    X_train = X_scaler.transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    \n",
    "    \n",
    "    # Use a linear SVC\n",
    "    svc = LinearSVC()\n",
    "\n",
    "    # Check the training time for the SVC\n",
    "    print('Training classifier...')\n",
    "    t0 = time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    print('%.3f seconds to train classifier.\\n' % (t1-t0))\n",
    "    test_params[cols[2]] = round(t1-t0, 3)\n",
    "\n",
    "    \n",
    "\n",
    "    # Check the prediction time for a single sample\n",
    "    print('Testing model...')\n",
    "    t0 = time.time()\n",
    "    pred = svc.predict(X_test)\n",
    "    t1 = time.time()\n",
    "    print('%.3f seconds to predict test classes\\n' % (t1-t0))\n",
    "    test_params[cols[3]] = round(t1-t0, 3)\n",
    "    \n",
    "    # Check the score of the SVC\n",
    "    print('Measuring model accuracy...')\n",
    "    acc = svc.score(X_test, y_test)\n",
    "    print('%.3f = Test Accuracy of SVC\\n' % acc)\n",
    "    test_params[cols[4]] = round(acc, 3)\n",
    "\n",
    "    # Save the classifier for use in other kernels\n",
    "    print('Saving SVC...')\n",
    "    joblib.dump(svc, clfname+'_clf.p')\n",
    "    print('Model saved.')\n",
    "    \n",
    "    # Record parameters used to perform the preceding and return\n",
    "    for i in range(len(keycols)):\n",
    "        test_params[keycols[i]] = [cspace, hog_channel, orient, pix_per_cell, cell_per_block][i]\n",
    "    \n",
    "    return test_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "139.338 seconds to extract features.\n",
      "\n",
      "Fitting scaler...\n",
      "1.033 seconds to fit scaler.\n",
      "\n",
      "Saving scaler...\n",
      "Scaler saved.\n",
      "Training classifier...\n",
      "15.755 seconds to train classifier.\n",
      "\n",
      "Testing model...\n",
      "0.162 seconds to predict test classes\n",
      "\n",
      "Measuring model accuracy...\n",
      "0.979 = Test Accuracy of SVC\n",
      "\n",
      "Saving SVC...\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "channels = ['ALL']\n",
    "orients = [15]\n",
    "ppcs = [18]\n",
    "cbps = [2]\n",
    "cspaces = ['YUV']\n",
    "\n",
    "cars = glob.glob('vehicles\\*\\*.png', recursive=True)\n",
    "nocars = glob.glob('non-vehicles\\*\\*.png', recursive=True)\n",
    "\n",
    "cols = ['t_featureExtract','t_fitScaler','t_trainClassifier','t_predictTestData','testAccuracy']\n",
    "keycols = ['cspace', 'hog_channel', 'orient', 'pix_per_cell', 'cell_per_block']\n",
    "results = pd.DataFrame(columns=keycols+cols)\n",
    "\n",
    "\n",
    "count = 0\n",
    "for cspace in cspaces:\n",
    "    for channel in channels:\n",
    "        for orient in orients:\n",
    "            for ppc in ppcs:\n",
    "                for cbp in cbps:\n",
    "                    r = model_measure(str(count), cars, nocars, cols, keycols,\n",
    "                                      hog_channel=channel, orient=orient, pix_per_cell=ppc, cell_per_block=cbp,\n",
    "                                      spatial_feat=True, hist_feat=True, hog_feat=True)\n",
    "                    count+=1\n",
    "                    results = results.append(r, ignore_index=True)\n",
    "                    results.to_csv('.\\\\modelSelection.csv')                        \n",
    "                        \n",
    "results.to_csv('.\\\\modelSelection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Permutations\n",
    "The following block is used to count the number of ways of permutating some of the configurable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60 ways of combining these parameters\n"
     ]
    }
   ],
   "source": [
    "channels = ['ALL']\n",
    "orients = [6, 9, 12]\n",
    "ppcs = [8, 16]\n",
    "cbps = [2, 4]\n",
    "cspaces = ['HSV', 'LUV', 'HLS', 'YUV', 'YCrCb']\n",
    "\n",
    "count = 0\n",
    "for cspace in cspaces:\n",
    "    for channel in channels:\n",
    "        for orient in orients:\n",
    "            for ppc in ppcs:\n",
    "                for cbp in cbps:\n",
    "                    count+=1\n",
    "                    \n",
    "print('There are',count,'ways of combining these parameters')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
